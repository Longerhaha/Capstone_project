{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 由于在windows10下获取文件符号链接权限非常麻烦，所以另辟蹊径。采用shutil.move的方式对train、test文件夹进行处理\n",
    "### 文件夹处理需要1分钟左右\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path deal time is 34.39030\n",
      "path deal time is 17.12331\n"
     ]
    }
   ],
   "source": [
    "root_src = 'D:\\Dogs vs. Cats'\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "os.chdir(root_src)\n",
    "\n",
    "\n",
    "\n",
    "#创建训练数据所需的文件夹\n",
    "\n",
    "def rmrf_mkdir(dirname,ctl='train'):\n",
    "    start = time.time()\n",
    "    if os.path.exists(dirname):\n",
    "        pass\n",
    "    else:\n",
    "        if ctl=='train':\n",
    "            os.mkdir(dirname)\n",
    "            os.mkdir('train2/cat')\n",
    "            os.mkdir('train2/dog')\n",
    "            #获取当前狗和猫图片的文件名\n",
    "            train_filenames = os.listdir('train')\n",
    "            train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "            train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "            #创建train2文件夹，并将cat类和dog类图片归类到不同的文件夹中\n",
    "            for filename in train_cat:\n",
    "                shutil.move('./train/'+filename, './train2/cat/'+filename)\n",
    "\n",
    "            for filename in train_dog:\n",
    "                shutil.move('./train/'+filename, './train2/dog/'+filename)\n",
    "        elif ctl=='test':\n",
    "            test_filenames = os.listdir(dirname.split('/')[0])\n",
    "            os.mkdir(dirname)\n",
    "            for filename in test_filenames:\n",
    "                shutil.move('test/'+filename,dirname+'/'+filename)\n",
    "        else:\n",
    "            pass\n",
    "    end = time.time()\n",
    "    print('path deal time is %.5f'%round(end-start,5))\n",
    "\n",
    "rmrf_mkdir('train2',ctl='train')  \n",
    "rmrf_mkdir('test/test2',ctl='test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通过预处理获得了ResNet50，InceptionV3，Xception三个模型的的特征参数,三个模型在GTX1070下跑获取参数时间大约花费40分钟。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "<class 'numpy.ndarray'> (25000, 2048)\n",
      "<class 'numpy.ndarray'> (12500, 2048)\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "<class 'numpy.ndarray'> (25000, 2048)\n",
      "<class 'numpy.ndarray'> (12500, 2048)\n",
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "<class 'numpy.ndarray'> (25000, 2048)\n",
      "<class 'numpy.ndarray'> (12500, 2048)\n",
      "one generator time is 2341 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "def write_gap(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    \n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator()\n",
    "    train_generator = gen.flow_from_directory(\"train2\", image_size, shuffle=False, \n",
    "                                              batch_size=16)\n",
    "    test_generator = gen.flow_from_directory(\"test\", image_size, shuffle=False, \n",
    "                                             batch_size=16, class_mode=None)\n",
    "    train = model.predict_generator(train_generator, len(train_generator.filenames)/16)\n",
    "    test = model.predict_generator(test_generator, len(test_generator.filenames)/16)\n",
    "    print(type(train),train.shape) \n",
    "    print(type(test),test.shape) \n",
    "    with h5py.File(\"gap_%s.h5\"%(MODEL.__name__)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)\n",
    "start = time.time()  \n",
    "write_gap(ResNet50, (224, 224))\n",
    "write_gap(InceptionV3, (299, 299), inception_v3.preprocess_input)\n",
    "write_gap(Xception, (299, 299), xception.preprocess_input)\n",
    "end = time.time()\n",
    "print('one generator time is %d s'%round(end-start))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
